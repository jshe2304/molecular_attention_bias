checkpoint_dir = "/scratch/midway3/jshe/molecular-attention-bias/U_G/BiasedAttentionTransformer/PowerLaw/E64H8D8"
# output_dir = "/scratch/midway3/jshe/molecular-attention-bias/U_G/BiasedAttentionTransformer/PowerLaw/E64H8D8/202508061841171/"

[model_config]
model_type = "BiasedAttentionTransformer"
n_tokens = 6
out_features = 3
E = 64
H = 8
D = 8
dropout = 0.1
radial_function_type = "PowerLaw"

[dataset_config]
dataset_type = "PointCloudDataset"
atoms_file = "/scratch/midway3/jshe/data/qm9/scaffolded/validation/atoms.npy"
coordinates_file = "/scratch/midway3/jshe/data/qm9/scaffolded/validation/coordinates.npy"
y_file = "/scratch/midway3/jshe/data/qm9/scaffolded/validation/y.npy"
y_labels_file = "/scratch/midway3/jshe/data/qm9/transformed/y_labels.npy"
y_mean_file = "/scratch/midway3/jshe/data/qm9/transformed/y_mean.npy"
y_std_file = "/scratch/midway3/jshe/data/qm9/transformed/y_std.npy"
target_labels = ['U', 'G']

